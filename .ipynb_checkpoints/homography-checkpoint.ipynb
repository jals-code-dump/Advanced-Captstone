{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import imutils\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_images(image, template, maxFeatures=500, keepPercent=0.4):\n",
    "\t# convert both the input image and template to grayscale\n",
    "\timageGray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\ttemplateGray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\t# use ORB to detect keypoints and extract (binary) local\n",
    "\t# invariant features\n",
    "\torb = cv2.ORB_create(maxFeatures)\n",
    "\t(kpsA, descsA) = orb.detectAndCompute(imageGray, None)\n",
    "\t(kpsB, descsB) = orb.detectAndCompute(templateGray, None)\n",
    "\n",
    "\t# match the features\n",
    "\tmethod = cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING\n",
    "\tmatcher = cv2.DescriptorMatcher_create(method)\n",
    "\tmatches = matcher.match(descsA, descsB, None)\n",
    "\n",
    "\t# sort the matches by their distance (the smaller the distance,\n",
    "\t# the \"more similar\" the features are)\n",
    "\tmatches = sorted(matches, key=lambda x:x.distance)\n",
    "\n",
    "\t# keep only the top matches\n",
    "\tkeep = int(len(matches) * keepPercent)\n",
    "\tmatches = matches[:keep]\n",
    "\n",
    "\t# allocate memory for the keypoints (x,y-coordinates) from the\n",
    "\t# top matches -- we'll use these coordinates to compute our\n",
    "\t# homography matrix\n",
    "\tptsA = np.zeros((len(matches), 2), dtype=\"float\")\n",
    "\tptsB = np.zeros((len(matches), 2), dtype=\"float\")\n",
    "\n",
    "\t# loop over the top matches\n",
    "\tfor (i, m) in enumerate(matches):\n",
    "\t\t# indicate that the two keypoints in the respective images\n",
    "\t\t# map to each other\n",
    "\t\tptsA[i] = kpsA[m.queryIdx].pt\n",
    "\t\tptsB[i] = kpsB[m.trainIdx].pt\n",
    "\n",
    "\t# compute the homography matrix between the two sets of matched\n",
    "\t# points\n",
    "\t(H, mask) = cv2.findHomography(ptsA, ptsB, method=cv2.RANSAC)\n",
    "\n",
    "\t# use the homography matrix to align the images\n",
    "\t(h, w) = template.shape[:2]\n",
    "\taligned = cv2.warpPerspective(image, H, (w, h))\n",
    "\n",
    "\t# return the aligned image\n",
    "\treturn aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IMG_20210706_0001.pdf0.jpg', 'IMG_20210706_0002.pdf0.jpg', 'IMG_20210706_0003.pdf0.jpg', 'IMG_20210706_0004.pdf0.jpg', 'IMG_20210706_0005.pdf0.jpg', 'IMG_20210706_0006.pdf0.jpg']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "input_path = \"C:\\\\GitHub\\\\mf724-ocr\\\\724_scans_jpg\\\\\"\n",
    "output_path = \"C:\\\\GitHub\\\\mf724-ocr\\\\oriented_scans\\\\\"\n",
    "target_image = cv2.imread(r'C:\\GitHub\\mf724-ocr\\mf724_images\\724_Wildcat__Airframe_.pdf1.jpg')\n",
    "images = os.listdir(input_path)\n",
    "print(images)\n",
    "\n",
    "for image in images:\n",
    "    image_path = input_path + image\n",
    "    scan_img = cv2.imread(image_path)\n",
    "    aligned = align_images(scan_img, target_image)\n",
    "    cv2.imwrite(output_path + image, aligned)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
