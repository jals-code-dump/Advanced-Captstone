{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training, Evaluation and Selection\n",
    "\n",
    "This notebook does the following:\n",
    "\n",
    "* Loads the MNIST and Kaggle AZ Datasets\n",
    "* Trains a KNN classifier and a ResNet Classifier\n",
    "* Tests accuracy of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14123534073417642930\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4153868288\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17105257790114846871\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.autograph.impl.api.do_not_convert(func=None)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "az_dataset_path = r\"C:\\GitHub\\mf724-ocr\\az-dataset\\A_Z Handwritten Data.csv\"\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow\n",
    "tensorflow.autograph.experimental.do_not_convert(func=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Labels for combined Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "labels = \"0123456789abcdefghijklmnopqrstuvwxyz\"\n",
    "dataset_labels = []\n",
    "for i in labels:\n",
    "    dataset_labels.append(i)\n",
    "\n",
    "print(dataset_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "\n",
    "Loads the MNIST and AZ datasets, then combines and splits them for training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1968bb19610>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#extract mnist data as per api\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "#combine all labels and images so we can split  later\n",
    "mn_images = np.vstack([train_X, test_X])\n",
    "mn_labels = np.hstack([train_y, test_y])\n",
    "MN = (mn_labels, mn_images)\n",
    "\n",
    "#test image to show data is loaded correctly\n",
    "print(\"Label:\", MN[0][0])\n",
    "plt.imshow(MN[1][0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: a\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load az dataset from local path\n",
    "df = pd.read_csv(az_dataset_path)\n",
    "\n",
    "#empty lists to fill with images and labels\n",
    "az_images = []\n",
    "az_labels = []\n",
    "\n",
    "#iterate through dataset extracting label and images\n",
    "for index, row in df.iterrows():\n",
    "    #row 0 contains the label\n",
    "    label = row[\"0\"]\n",
    "    #all other row contents are the images\n",
    "    image = np.array(row[1:], dtype=\"uint8\")\n",
    "    #rearrange the array to an image format\n",
    "    image = image.reshape((28, 28))\n",
    "    az_images.append(image)\n",
    "    #we add 10 as the labels will be after the 0-9 labels\n",
    "    az_labels.append(label+10)\n",
    "\n",
    "#load images and labels into single arrays of correct format\n",
    "az_images = np.array(az_images, dtype=\"float32\")\n",
    "az_labels = np.array(az_labels, dtype=\"int\")\n",
    "#create a tuple for AZ data\n",
    "AZ = (az_labels, az_images)\n",
    "#show a test image to prove correct loading\n",
    "plt.imshow(AZ[1][0], cmap=\"gray\")\n",
    "print(\"Label:\", dataset_labels[AZ[0][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a single image and label dataset from both datasets\n",
    "comb_images = np.vstack([MN[1], AZ[1]])\n",
    "comb_labels = np.hstack([MN[0], AZ[0]])\n",
    "\n",
    "#flatten images for knn model\n",
    "flat_images = [x.flatten() for x in comb_images]\n",
    "#split test sets for KNN\n",
    "ktrainX, ktestX, ktrainY, ktestY = train_test_split(flat_images, comb_labels, test_size=0.25, random_state=1)\n",
    "\n",
    "#resnet requires images be a minimum of 32, 32, 1\n",
    "#therefore we need to resize them accordingly\n",
    "comb_images = [cv2.resize(image, (32, 32)) for image in comb_images]\n",
    "comb_images = np.array(comb_images, dtype=\"float32\")\n",
    "\n",
    "#now we need to add the x,x,1 and normalise the values to be between 0 and 1\n",
    "comb_images = np.expand_dims(comb_images, axis=-1)\n",
    "comb_images /= 255.0\n",
    "\n",
    "#split test sets for CNN, using same randomstate to ensure no bias\n",
    "trainX, testX, trainY, testY = train_test_split(comb_images, comb_labels, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2334/2334 [==============================] - 184s 76ms/step - loss: 0.3818 - accuracy: 0.9010 - val_loss: 0.1836 - val_accuracy: 0.9470\n",
      "Fitting time: 184.21516108512878\n",
      "Predictions time: 41.882609367370605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.63      0.71      1721\n",
      "           1       0.96      0.99      0.98      1919\n",
      "           2       0.95      0.83      0.89      1763\n",
      "           3       0.86      0.95      0.90      1765\n",
      "           4       0.96      0.91      0.93      1724\n",
      "           5       0.89      0.85      0.87      1632\n",
      "           6       0.95      0.98      0.97      1764\n",
      "           7       0.83      0.99      0.91      1772\n",
      "           8       0.97      0.81      0.88      1725\n",
      "           9       0.94      0.93      0.94      1726\n",
      "           a       0.98      0.92      0.95      3473\n",
      "           b       0.93      0.94      0.93      2199\n",
      "           c       0.91      0.99      0.95      5821\n",
      "           d       0.90      0.95      0.92      2481\n",
      "           e       0.99      0.90      0.94      2866\n",
      "           f       0.97      0.89      0.93       288\n",
      "           g       0.98      0.86      0.92      1436\n",
      "           h       0.91      0.92      0.92      1767\n",
      "           i       0.96      0.95      0.96       278\n",
      "           j       0.90      0.92      0.91      2154\n",
      "           k       0.92      0.96      0.94      1449\n",
      "           l       0.98      0.96      0.97      2860\n",
      "           m       0.99      0.96      0.97      3084\n",
      "           n       0.95      0.98      0.97      4864\n",
      "           o       0.95      0.94      0.95     14392\n",
      "           p       0.98      0.98      0.98      4928\n",
      "           q       0.93      0.95      0.94      1406\n",
      "           r       0.98      0.95      0.97      2869\n",
      "           s       0.98      0.96      0.97     12270\n",
      "           t       0.97      0.99      0.98      5441\n",
      "           u       0.93      1.00      0.96      7241\n",
      "           v       0.98      0.95      0.97      1082\n",
      "           w       0.99      0.94      0.97      2721\n",
      "           x       0.98      0.93      0.96      1526\n",
      "           y       0.93      0.97      0.95      2719\n",
      "           z       0.82      0.98      0.90      1487\n",
      "\n",
      "    accuracy                           0.95    110613\n",
      "   macro avg       0.94      0.93      0.93    110613\n",
      "weighted avg       0.95      0.95      0.95    110613\n",
      "\n",
      "INFO:tensorflow:Assets written to: C:\\GitHub\\mf724-ocr\\ResNet50\\assets\n"
     ]
    }
   ],
   "source": [
    "#instantiate the resnet model with randomised weights, input shape and amount of classes\n",
    "model = ResNet50(weights=None, input_shape=(32, 32, 1), classes=len(dataset_labels))\n",
    "\n",
    "#compile model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "#train model on training data, using 10% for validation\n",
    "#batch size uses ~90% of a GTX 1080 TI\n",
    "startTime = time.time()\n",
    "model.fit(trainX, trainY, batch_size=128, epochs=1, validation_split=0.1, verbose=1)\n",
    "print(\"Fitting time:\", time.time()-startTime)\n",
    "\n",
    "#carry out predictions\n",
    "startTime = time.time()\n",
    "preds = model.predict(testX)\n",
    "print(\"Predictions time:\", time.time()-startTime)\n",
    "\n",
    "#print a classification report to see final scores\n",
    "print(classification_report(testY, preds.argmax(axis=1), target_names=dataset_labels))\n",
    "\n",
    "#save the model\n",
    "model.save(\"C:\\GitHub\\mf724-ocr\\ResNet50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting time: 1088.7480635643005\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[28 34 27 ... 28  3  6].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-4bc8f4a4eedf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#predict on validation data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mstartTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mktestY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predictions time:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstartTime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mktestY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \"\"\"\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    554\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[28 34 27 ... 28  3  6].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "#instantiate a KNN classifier\n",
    "knn = KNeighborsClassifier(len(dataset_labels), n_jobs=-1)\n",
    "\n",
    "#monitor time taken to train and predict\n",
    "startTime = time.time()\n",
    "knn.fit(ktrainX, ktrainY)\n",
    "print(\"Fitting time:\", time.time()-startTime)\n",
    "\n",
    "#predict on validation data\n",
    "startTime = time.time()\n",
    "preds = knn.predict(ktestX)\n",
    "print(\"Predictions time:\", time.time()-startTime)\n",
    "print(classification_report(ktestY, preds, target_names=dataset_labels))\n",
    "\n",
    "knn.save(\"C:\\GitHub\\mf724-ocr\\KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results:\n",
    "\n",
    "### ResNet50:\n",
    "\n",
    "Weigted AVG F1 Score 0.96\n",
    "Training Time 139 seconds\n",
    "Full Prediction Time 33 seconds\n",
    "Single Prediction Time 0.0003 seconds\n",
    "\n",
    "### KNN\n",
    "\n",
    "Weigted AVG F1 Score 0.91\n",
    "Training Time 1088 seconds\n",
    "Full Prediction Time 7267 seconds\n",
    "Single Prediction Time 0.07 seconds\n",
    "\n",
    "The ResNet50 model out performs the KNN model in every metric, and will be used as the final model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
